{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pynapple as nap\n",
    "import h5py\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "from caiman.source_extraction.cnmf.cnmf import load_CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file(directory, substrings=None, extension=\".csv\", recursive=False):\n",
    "    \"\"\"\n",
    "    Find a single file in a directory based on specified substrings and extension.\n",
    "    \"\"\"\n",
    "    substrings = substrings or [\"timestamps\"]\n",
    "    directory = Path(directory)\n",
    "\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"Directory {directory} does not exist.\")\n",
    "\n",
    "    files = directory.rglob(\"*\") if recursive else directory.iterdir()\n",
    "    matched_files = [\n",
    "        file for file in files\n",
    "        if file.is_file()\n",
    "        and all(sub.lower() in file.name.lower() for sub in substrings)\n",
    "        and file.suffix.lower() == extension.lower()\n",
    "    ]\n",
    "\n",
    "    if not matched_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No file found in {directory} matching substrings {substrings} and extension '{extension}'.\"\n",
    "        )\n",
    "    if len(matched_files) > 1:\n",
    "        raise ValueError(\n",
    "            f\"Multiple files found in {directory} matching substrings {substrings} and extension '{extension}': \"\n",
    "            f\"{', '.join(f.name for f in matched_files)}\"\n",
    "        )\n",
    "    return matched_files[0]\n",
    "\n",
    "\n",
    "def load_dlc_data(dlc_dir):\n",
    "    \"\"\"\n",
    "    Load DLC data by searching for specific files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dlc_file = find_file(dlc_dir, [\"linearMay29shuffle1\", \"filtered\"], \".h5\")\n",
    "        return pd.read_hdf(dlc_file), dlc_file.name\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        logging.error(f\"DLC data loading failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def load_caiman_data(caiman_dir):\n",
    "    \"\"\"\n",
    "    Load Caiman results from the directory.\n",
    "    \"\"\"\n",
    "    caiman_file = caiman_dir / \"caiman_results.hdf5\"\n",
    "    if caiman_file.exists():\n",
    "        try:\n",
    "            return load_CNMF(str(caiman_file)), caiman_file.name\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading Caiman data: {e}\")\n",
    "    else:\n",
    "        logging.error(f\"Caiman results file not found at {caiman_file}\")\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_session_data_old(base_dir, date_number):\n",
    "    \"\"\"\n",
    "    Load DLC results, Caiman results, and timestamps for a given session.\n",
    "    \"\"\"\n",
    "    session_dir = Path(base_dir) / str(date_number)\n",
    "    data = {}\n",
    "\n",
    "    # Load DLC data\n",
    "    data[\"dlc\"], data[\"dlc_filename\"] = load_dlc_data(session_dir / \"dlc\")\n",
    "\n",
    "    # Load Caiman data\n",
    "    data[\"caiman\"], data[\"caiman_filename\"] = load_caiman_data(session_dir / \"caiman\")\n",
    "\n",
    "    # Load Timestamps\n",
    "    try:\n",
    "        timestamp_file = find_file(session_dir, [\"timestamps\"], \".csv\")\n",
    "        data[\"timestamps\"] = pd.read_csv(timestamp_file)\n",
    "        data[\"timestamps_filename\"] = timestamp_file.name\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        logging.error(f\"Timestamps loading failed: {e}\")\n",
    "        data[\"timestamps\"], data[\"timestamps_filename\"] = None, None\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_session_data(base_dir):\n",
    "    \"\"\"\n",
    "    Load DLC results, Caiman results, and timestamps for a given session.\n",
    "    \"\"\"\n",
    "    session_dir = Path(base_dir)\n",
    "    data = {}\n",
    "\n",
    "    # Load DLC data\n",
    "    data[\"dlc\"], data[\"dlc_filename\"] = load_dlc_data(session_dir / \"dlc\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory and date number\n",
    "base_dir = \"/media/toor/T7Shield/AgingMiceNWB/sub-Mouse1637\"\n",
    "date_number = 20240628\n",
    "Mouse_id = 'Mouse1637'\n",
    "\n",
    "# Load session data\n",
    "session_data = load_session_data_old(base_dir, date_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from session data\n",
    "dlc_data = session_data.get('dlc')\n",
    "dlc_filename = session_data.get('dlc_filename')\n",
    "\n",
    "caiman_data = session_data.get('caiman')\n",
    "caiman_filename = session_data.get('caiman_filename')\n",
    "\n",
    "timestamps = session_data.get('timestamps')\n",
    "timestamps_filename = session_data.get('timestamps_filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dlc_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose bodypart with higest confidence (loosely defined as the bodypart with the highest likelihood average)\n",
    "# usually it's just bodypart 2\n",
    "likelihood_averages = {\n",
    "    \"bodypart1\": dlc_data.iloc[:, 2].astype(float).mean(),\n",
    "    \"bodypart2\": dlc_data.iloc[:, 5].astype(float).mean(),\n",
    "    \"bodypart3\": dlc_data.iloc[:, 8].astype(float).mean(),\n",
    "    \"objectA\": dlc_data.iloc[:, 11].astype(float).mean()\n",
    "}\n",
    "highest_confidence = max(likelihood_averages, key=likelihood_averages.get)\n",
    "print(str(highest_confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bodypart1's x and y coordinates, starting from the third row (index 2)\n",
    "bodypart2_x = dlc_data.iloc[:, 3].astype(float)  # x coordinates\n",
    "bodypart2_y = dlc_data.iloc[:, 4].astype(float)  # y coordinates\n",
    "bodypart2_likelihood = dlc_data.iloc[:, 5].astype(float)  \n",
    "frame_idx = dlc_data.index.astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a likelihood threshold\n",
    "likelihood_threshold = 0.9\n",
    "\n",
    "# Create a mask for low-likelihood points\n",
    "low_likelihood_mask = bodypart2_likelihood < likelihood_threshold\n",
    "\n",
    "# Handle low-likelihood points: Option 1 - Set them to NaN\n",
    "bodypart2_x[low_likelihood_mask] = None\n",
    "bodypart2_y[low_likelihood_mask] = None\n",
    "\n",
    "# Interpolate missing values for continuity =  calculate from previous and next values\n",
    "# Ensures data remain continuous and smooth\n",
    "bodypart2_x = bodypart2_x.interpolate()\n",
    "bodypart2_y = bodypart2_y.interpolate()\n",
    "\n",
    "# Display a summary\n",
    "print(f\"Total points: {len(bodypart2_likelihood)}\")\n",
    "print(f\"Low-likelihood points: {low_likelihood_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create an interactive line chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the data for the plot\n",
    "fig.add_trace(go.Scatter(y=bodypart2_y, mode='lines', name='X Coordinates'))\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title='Bodypart1 X Coordinate Over Time',\n",
    "    xaxis_title='Time (frames)',\n",
    "    yaxis_title='X Coordinates'\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear track start time based on y thrshold -  I think this is enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_surpass_index = bodypart2_y[bodypart2_y < 730].index[0]\n",
    "frame_rate = 25\n",
    "start_time_seconds = first_surpass_index/frame_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Video Trimming for a single directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory\n",
    "base_directory = \"/media/toor/T7Shield/AgingMiceNWB/sub-Mouse1637/ThirdRound/Linear\"\n",
    "\n",
    "likelihood_threshold = 0.9\n",
    "frame_rate = 25\n",
    "\n",
    "# Directory to change to before running the bash script\n",
    "bash_working_directory = \"/home/toor/Desktop/stability-preprocessing/\"\n",
    "os.chdir(bash_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(base_directory, topdown=False):    \n",
    "    # dlc_file = None\n",
    "    miniscope_file = None\n",
    "    behavior_file = None\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".h5\") and 'filtered' in file:\n",
    "            print(file)\n",
    "            dlc_file = os.path.join(root, file)\n",
    "            dlc_data = pd.read_hdf(dlc_file)\n",
    "            bodypart2_y = dlc_data.iloc[:, 4].astype(float)  # y coordinates\n",
    "            bodypart2_likelihood = dlc_data.iloc[:, 5].astype(float)\n",
    "            low_likelihood_mask = bodypart2_likelihood < likelihood_threshold\n",
    "            bodypart2_y[low_likelihood_mask] = None\n",
    "            bodypart2_y = bodypart2_y.interpolate()\n",
    "            first_surpass_index = bodypart2_y[bodypart2_y < 715].index[0]\n",
    "            start_time_seconds = first_surpass_index/frame_rate \n",
    "            # # DELETE AFTER VISUAL CHECK\n",
    "            # fig = go.Figure()\n",
    "            # fig.add_trace(go.Scatter(y=bodypart2_y, mode='lines', name='X Coordinates'))\n",
    "            # # Add titles and labels\n",
    "            # fig.update_layout(\n",
    "            #     title=str(file),\n",
    "            #     xaxis_title='Time (frames)',\n",
    "            #     yaxis_title='X Coordinates')\n",
    "            # fig.show()\n",
    "            # print(str(first_surpass_index)) \n",
    "            # #STOP DELETING   \n",
    "        # Look for the video files in the current directory\n",
    "        if \"miniscope\" in file and file.endswith(\".avi\"):\n",
    "            miniscope_file = os.path.join(root, file)\n",
    "            # print(f\"Miniscope file found: {miniscope_file}\")\n",
    "        elif file.startswith(\"behavior\") and not file.startswith(\"behaviorLinear\") and file.endswith(\".avi\"):\n",
    "            behavior_file = os.path.join(root, file)\n",
    "            # print(f\"Behavior file found: {behavior_file}\")\n",
    "\n",
    "        # Check if all required files are found\n",
    "    if miniscope_file and behavior_file and dlc_file:\n",
    "        print(str(start_time_seconds))\n",
    "        print(str(dlc_file))\n",
    "        print(str(miniscope_file))\n",
    "        print(str(behavior_file))   \n",
    "    # Trim each video file to 15 minutes using ffmpeg\n",
    "        for video_file in [miniscope_file, behavior_file]:  # no need to trim home cage video\n",
    "            # Define output file name\n",
    "            output_file = os.path.join(\n",
    "                root, \n",
    "                f\"/media/toor/T7Shield/Mouse1637/Linear/Linear_{os.path.basename(video_file)}\"\n",
    "            )\n",
    "            \n",
    "            # Construct the ffmpeg command\n",
    "            ffmpeg_command = [\n",
    "                \"ffmpeg\",\n",
    "                \"-n\",  # Overwrite output files without asking\n",
    "                \"-ss\", str(start_time_seconds),  # Start time in seconds\n",
    "                \"-i\", video_file,          # Input file\n",
    "                \"-t\", \"900\",             # Duration (15 minutes in seconds)\n",
    "                \"-c:v\", \"copy\",           # Copy video codec (no re-encoding)\n",
    "                \"-c:a\", \"copy\",           # Copy audio codec (no re-encoding)\n",
    "                output_file               # Output file\n",
    "            ]\n",
    "            \n",
    "            print(f\"Trimming video: {' '.join(ffmpeg_command)}\")\n",
    "            try:\n",
    "                subprocess.run(ffmpeg_command, check=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error while trimming video {video_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"Missing required files in directory: {root}\")\n",
    "        if not miniscope_file:\n",
    "            print(\"  - Miniscope file is missing.\")\n",
    "        if not behavior_file:\n",
    "            print(\"  - Behavior file is missing.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stability-preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
